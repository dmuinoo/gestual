{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmuinoo/gestual/blob/main/YoloX_Custom_Training_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YoloX Custom Training - Emotion Detection**\n",
        "\n",
        "\n",
        "![image:png](https://github.com/Megvii-BaseDetection/YOLOX/raw/main/assets/logo.png)\n",
        "\n",
        "\n",
        "<p>YoloX just got released, and it is better and faster than, YoloR, YoloV4, Scaled YoloV4, YoloV5 and PP-YOLOv2.</p>\n",
        "\n",
        "\n",
        "<p>In this Tutorial let us learn how to do Emotion Detection by doing custom training on YoloX. All right here and right now. No time to waste guys, lets get started!!</p>\n",
        "\n",
        "\n",
        "\n",
        "# **Want to Become a YOLOX Expert?**\n",
        "üíªGet Started with YOLOX [Get Started](https://www.augmentedstartups.com/yolox-registration). <br>\n",
        "‚≠ê Download the Code at the [AI Vision Store](https://augmentedstartups.info/VisionStore)<br>\n",
        "‚òï Buy me [Chai/Coffee](https://bit.ly/BuymeaCoffeeAS)\n",
        "\n",
        "# **About US**\n",
        "[Augmented Startups](https://www.augmentedstartups.com) provides tutorials in AI Computer Vision and Augmented Reality. With over **95K subscribers** on our channel, we teach state-of-art models and build apps and projects that solve real-world problems. \n",
        "\n",
        "![image:png](https://drive.google.com/uc?export=view&id=1ps6pORV6b4eOoQAljv8s-hTq9YAaIN3b)\n",
        "\n",
        "<br>\n",
        "\n",
        "#From the Author   \n",
        "## hey there <img src=\"https://media.giphy.com/media/hvRJCLFzcasrR4ia7z/giphy.gif\" width=\"25px\">\n",
        "\n",
        "**I am Rohit Kukreja - A Computer Vision & Deep Learning Practitioner**\n",
        "\n",
        "\n",
        "<a href=\"https://github.com/rohitkuk\">\n",
        "  <img align=\"left\" alt=\"Rohit Kukreja Github\" width=\"22px\" src=\"https://cdn-icons-png.flaticon.com/512/25/25231.png\" />\n",
        "</a>\n",
        "<a href=\"https://twitter.com/_Rohitkukreja\">\n",
        "  <img align=\"left\" alt=\"Rohit Kukreja | Twitter\" width=\"22px\" src=\"https://raw.githubusercontent.com/peterthehan/peterthehan/master/assets/twitter.svg\" />\n",
        "</a>\n",
        "<a href=\"https://www.linkedin.com/in/rohitkuk/\">\n",
        "  <img align=\"left\" alt=\"Rohit's's LinkedIN\" width=\"22px\" src=\"https://raw.githubusercontent.com/peterthehan/peterthehan/master/assets/linkedin.svg\" />\n",
        "</a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3iqeNMmoQax_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "3aPYEhGqQEFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGDVg8Xg0G9o"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE1vQ2-LCyPv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/dmuinoo/gestual/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVlxlYYBR6z"
      },
      "source": [
        "# Install YOLOX Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igwruhYxE_a7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/gestual\n",
        "!pip3 install -U pip && pip3 install -r requirements.txt\n",
        "!pip3 install -v -e .  \n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "# May need to change in the future if Colab no longer uses CUDA 11.0\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llsu3xhVBZYC"
      },
      "source": [
        "#Install Nvidia Apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksHd57LFFMzK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdiT0rJBmRA"
      },
      "source": [
        "# Import the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-g8RrAW0Y1a"
      },
      "outputs": [],
      "source": [
        "%cd /content/gestual/\n",
        "!curl -L \"https://public.roboflow.com/ds/RM02OBPfKD?key=6IpgAWtQ0U\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr4cOxxbVuHB"
      },
      "outputs": [],
      "source": [
        "root = \"/content/gestual/train/\"\n",
        "%mkdir /content/gestual/datasets/VOCdevkit/\n",
        "!cp -a \"/content/gestual/train/.\" \"/content/gestual/datasets/VOCdevkit\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZSFjXLByrv"
      },
      "source": [
        "# Prepare dataset as per VOC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xTRtDWrIw_D"
      },
      "outputs": [],
      "source": [
        "%cd /content/gestual/\n",
        "%mkdir \"/content/gestual/datasets/VOCdevkit/VOC2007\"\n",
        "!python3 voc_txt.py \"/content/gestual/datasets/VOCdevkit/\"\n",
        "%mkdir \"/content/gestual/datasets/VOCdevkit/VOC2012\"\n",
        "!cp -r \"/content/gestual/datasets/VOCdevkit/VOC2007/.\" \"/content/gestual/datasets/VOCdevkit/VOC2012\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW8iyuMyB3bc"
      },
      "source": [
        "#Update the default classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohuAE541Nug"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h5PM8Ft1OjG"
      },
      "outputs": [],
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/gestual/yolox/data/datasets/voc_classes.py\n",
        "\n",
        "VOC_CLASSES = (\n",
        "  'pistol'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu6_LzErQRSU"
      },
      "outputs": [],
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/gestual/yolox/data/datasets/coco_classes.py\n",
        "\n",
        "COCO_CLASSES = (\n",
        "  'pistol'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxA0JmWqwU_M"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 1\n",
        "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/gestual/exps/example/yolox_voc/yolox_voc_s.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJPTSiAZaLq"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsOCh9hRKbIw"
      },
      "outputs": [],
      "source": [
        "#Download the weights\n",
        "%cd /content/gestual\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6mtJ5j7ZDYw"
      },
      "outputs": [],
      "source": [
        "%env OUT_DIR= /content/gdrive/MyDrive/gestual\n",
        "!mkdir = /content/gdrive/MyDrive/gestual\n",
        "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /content/gestual/yolox_s.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMuC6_dbwumC"
      },
      "source": [
        "# Inference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "FY1LVqK8w45C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env OUT_DIR= /content/gdrive/MyDrive/gestual\n",
        "VIDEO_PATH = \"/content/gdrive/MyDrive/yolo/prueba2.mp4\"\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/gestual/YOLOX_outputs/yolox_voc_s/last_epoch_ckpt.pth.tar\"\n",
        "!python tools/demo.py video -f /content/gestual/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {VIDEO_PATH} --conf 0.25 --nms 0.45 --save_result --device gpu"
      ],
      "metadata": {
        "id": "Yupnu5d4wumJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3aPYEhGqQEFl",
        "VfVlxlYYBR6z",
        "llsu3xhVBZYC",
        "UEdiT0rJBmRA",
        "agZSFjXLByrv",
        "BW8iyuMyB3bc",
        "eoJPTSiAZaLq"
      ],
      "name": "YoloX Custom Training - Emotion Detection ",
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}